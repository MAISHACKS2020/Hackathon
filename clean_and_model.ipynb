{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 2,
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pro1 = pd.read_csv(\"/home/jahnic/Git/Hackathon/pro_trump2_400.csv\",index_col=0)\n",
    "data_pro2 = pd.read_csv(\"/home/jahnic/Git/Hackathon/pro_trump2.csv\",index_col=0)\n",
    "data_anti = pd.read_csv(\"/home/jahnic/Git/Hackathon/anti_trump.csv\",index_col=0)"
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"pro_trump2_400.csv\",index_col=0)"
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices in pro trump data set that are either anti trump or neither\n",
    "anti_index = [395, 400, 403, 407, 413, 417, 4120, 422, 426, 427, 431, 432, 435, 437, 438, 449, 451, 457, 459, 462, 463, 470, 472, 474, 477, 478, 479, 482, 484, 485, 491, 493, 497, 499, 503, 505, 509, 518, 519, 520, 523, 530, 532, 533, 534, 535, 538, 541, 545, 548, 551, 554, 557,558, 561,  562, 563, 564, 569, 570, 577, 579, 580, 583, 585, 586, 590, 609, 610, 615, 619, 622, 623, 624, 625, 626, 628, 630, 632, 634, 637, 638, 644, 647, 652, 653, 657, 658, 660, 667, 668, 670, 671, 674, 676, 684, 686, 688, 695, 696, 699, 700, 704, 706, 707, 708, 709, 710, 711, 714, 717, 721, 722, 725, 726, 728, 734, 735, 738, 739, 741, 742, 743, 747, 749, 752, 753, 754, 757, 758, 759, 760, 762, 764, 765, 766, 768, 771, 773, 777, 778, 782, 784, 785,786, 789, 795, 796,797, 799, 800, 801, 802, 803, 806, 807, 809, 810, 812, 817, 818, 820, 822, 823, 826, 828, 832, 835, 836, 837, 843, 846]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_pro[data_pro.apply(lambda x: x.index in [522, 533, 534])]\n",
    "anti_mask = data_pro2.apply(lambda x: x.name in anti_index, axis=1)\n",
    "\n",
    "# pro and anti trump comments in data_pro2\n",
    "anti = data_pro2[anti_mask]\n",
    "pro = data_pro2[anti_mask.apply(lambda x: not x)].iloc[400: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 500)\n",
    "\n",
    "delete = [484, 509, 541, 734,]\n",
    "anti.drop(delete, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pro = pd.concat([data_pro1, pro], axis=0, ignore_index=True)\n",
    "data_pro.fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nInt64Index: 1594 entries, 0 to 795\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   tweets  1594 non-null   object \n 1   label   1594 non-null   float64\ndtypes: float64(1), object(1)\nmemory usage: 37.4+ KB\n"
    }
   ],
   "source": [
    "data = pd.concat([data_pro, anti, data_anti])\n",
    "data.fillna(0, inplace=True)\n",
    "data.columns = ['tweets', 'label']\n",
    "data.info()"
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\"tweets\", \"label\"]"
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_mentions(tweet):\n",
    "    \"\"\"Removes mentions of the form @NAME123\"\"\"\n",
    "    x = re.sub('@[a-zA-Z0-9]+', \"\", tweet)\n",
    "    return x\n",
    "\n",
    "def remove_hashtags(tweet):\n",
    "    x = re.sub('#[a-zA-Z0-9]+', \"\", tweet)\n",
    "    return x"
=======
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"So after Biden wins, what do we do with the c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"@GOPLeader @GoJackFlynn Please. \\nJust #Remov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"@Jeromep81422970 @stillgray And I thought #Tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Seeing a lot of #TrumpSupporters taking their...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"The bigger question is, why are hundreds of p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>\"#TrumpSupporters you suck\\n#Republicans you s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>\"BIDEN‚ÄôS WISCONSIN WELCOME PARTY: Just look at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>\"Name me one single way @JoeBiden can win over...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>\"Donald can't say there'll be a peaceful trans...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>\"@benshapiro Looking for the #TrumpSupporters ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweets  label\n",
       "0    \"So after Biden wins, what do we do with the c...      1\n",
       "1    \"@GOPLeader @GoJackFlynn Please. \\nJust #Remov...      1\n",
       "2    \"@Jeromep81422970 @stillgray And I thought #Tr...      0\n",
       "3    \"Seeing a lot of #TrumpSupporters taking their...      0\n",
       "4    \"The bigger question is, why are hundreds of p...      0\n",
       "..                                                 ...    ...\n",
       "388  \"#TrumpSupporters you suck\\n#Republicans you s...      0\n",
       "389  \"BIDEN‚ÄôS WISCONSIN WELCOME PARTY: Just look at...      1\n",
       "390  \"Name me one single way @JoeBiden can win over...      1\n",
       "391  \"Donald can't say there'll be a peaceful trans...      1\n",
       "397  \"@benshapiro Looking for the #TrumpSupporters ...      0\n",
       "\n",
       "[254 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 for anti-trump, 1 for pro-trump, 2 for unknown\n",
    "data = data[data.iloc[:,1]!=2]\n",
    "data"
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 127,
=======
   "execution_count": 25,
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "                                                tweets  label\n0    &quot;So after Biden wins, what do we do with the c...    0.0\n1    &quot;  Please. \\nJust #RemovePelosi now.\\nShe is c...    1.0\n2    &quot;  And I thought #TrumpSupporters were the bot...    0.0\n3    &quot;Seeing a lot of #TrumpSupporters taking their...    0.0\n4    &quot;The bigger question is, why are hundreds of p...    0.0\n..                                                 ...    ...\n791  &quot;Now yo ass wanna wear a mask since u and yo b...    0.0\n792    &quot;Two newsflashes: #TrumpIsRacist #TrumpIsBroke&quot;    0.0\n793   &quot;   Me too\\n#VoteHimOut https://t.co/IgzUSPcGak&quot;    0.0\n794  &quot;üòÇüòÇüòÇ\\nWhy the fuck should Biden be punished fo...    0.0\n795  &quot;As the moderator of tonight&#39;s debate, Chris W...    0.0\n\n[1594 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"So after Biden wins, what do we do with the c...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"  Please. \\nJust #RemovePelosi now.\\nShe is c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"  And I thought #TrumpSupporters were the bot...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"Seeing a lot of #TrumpSupporters taking their...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"The bigger question is, why are hundreds of p...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>791</th>\n      <td>\"Now yo ass wanna wear a mask since u and yo b...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>792</th>\n      <td>\"Two newsflashes: #TrumpIsRacist #TrumpIsBroke\"</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>793</th>\n      <td>\"   Me too\\n#VoteHimOut https://t.co/IgzUSPcGak\"</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>794</th>\n      <td>\"üòÇüòÇüòÇ\\nWhy the fuck should Biden be punished fo...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>795</th>\n      <td>\"As the moderator of tonight's debate, Chris W...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1594 rows √ó 2 columns</p>\n</div>"
=======
      "text/plain": [
       "153"
      ]
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
     },
     "execution_count": 25,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 127
    }
   ],
   "source": [
    "data['tweets'] = data.tweets.apply(lambda x: remove_mentions(x))\n",
    "data"
=======
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of pro-trump tweets\n",
    "sum(data['label'])"
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
=======
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## add a fake label\n",
    "# fakeLabel = np.random.randint(2,size=462)\n",
    "# data[\"label\"] = fakeLabel\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/xiao/.local/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /home/xiao/.local/lib/python3.8/site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: click in /home/xiao/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/xiao/.local/lib/python3.8/site-packages (from nltk) (4.50.0)\n",
      "Requirement already satisfied: regex in /home/xiao/.local/lib/python3.8/site-packages (from nltk) (2020.9.27)\n"
     ]
    }
   ],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/xiao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# basic modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "\n",
    "# text preprocessing modules\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from tokenize import tokenize\n",
    "\n",
    "\n",
    "# models\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
<<<<<<< HEAD
    "from sklearn.model_selection import train_test_split"
=======
    "from sklearn.model_selection import train_test_split\n"
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 129,
=======
   "execution_count": 14,
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/xiao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/xiao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#dowload stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "#download punkt for word_tokensize\n",
    "nltk.download('punkt')\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
=======
   "execution_count": 15,
   "metadata": {},
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finally\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(input_data):\n",
    "    '''\n",
    "    input_data: a vector of messages\n",
    "    output: stopwords removed\n",
    "    '''\n",
    "    # required:\n",
    "    # import nltk\n",
    "    # dowload stopwords\n",
    "    # nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    output = []\n",
    "    for i, sentence in enumerate(input_data):\n",
    "        #words = word_tokenize(sentence)  #will not remove punctuations and numbers\n",
    "        sms = re.sub(\"[^a-zA-Z]\", \" \", sentence).lower()\n",
    "        words = word_tokenize(sms)\n",
    "        filtered_sentence = [w for w in words if not w in stop_words]\n",
    "        output.append(\" \".join(filtered_sentence).lower() )\n",
    "    return output\n",
    "\n",
    "#https://rustyonrampage.github.io/text-mining/2017/11/28/spelling-correction-with-python-and-nltk.html\n",
    "def reduce_lengthening(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)\n",
    "\n",
    "print(reduce_lengthening( \"finallllllly\" ) )\n",
    "\n",
    "def remove_stemmers(input_data):\n",
    "    '''\n",
    "    input: a vector of messages \n",
    "    output: remvove stemmers and punctuations\n",
    "        all lower letter \n",
    "        stemmer removed\n",
    "        punctuations removed\n",
    "    '''\n",
    "    ## require download punkt for word_tokensize\n",
    "    #nltk.download('punkt')\n",
    "    #stemmer = PorterStemmer()\n",
    "    \n",
    "    ## https://towardsdatascience.com/multi-class-text-classification-with-sklearn-and-nltk-in-python-a-software-engineering-use-case-779d4a28ba5\n",
    "    ## df_train[\"cleaned\"] = df_train['message'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "    output = []\n",
    "    for i, sentence in enumerate(input_data):\n",
    "        sms = re.sub(\"[^a-zA-Z]\", \" \", sentence) \n",
    "        words = word_tokenize(sms)\n",
    "        filtered_sentence = [stemmer.stem(reduce_lengthening(w)) for w in words]\n",
    "        output.append(\" \".join(filtered_sentence) )\n",
    "        \n",
    "    return output\n",
    "\n",
    "def messages_preprocess(input_data):      \n",
    "    return remove_stemmers(remove_stopwords(input_data))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
=======
   "execution_count": 16,
   "metadata": {},
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   "outputs": [
    {
     "name": "stdout",
<<<<<<< HEAD
     "text": "time used: 1.6435441970825195\n"
=======
     "output_type": "stream",
     "text": [
      "time used: 0.13688087463378906\n"
     ]
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
    },
    {
     "data": {
<<<<<<< HEAD
      "text/plain": "                                              tweets  label                                            cleaned\n0  &quot;So after Biden wins, what do we do with the c...    0.0                                     biden win cult\n1  &quot;  Please. \\nJust #RemovePelosi now.\\nShe is c...    1.0  pleas njust removepelosi nshe constantli lie n...\n2  &quot;  And I thought #TrumpSupporters were the bot...    0.0  thought trumpsupport bot trump http co r vgqv uob\n3  &quot;Seeing a lot of #TrumpSupporters taking their...    0.0  see lot trumpsupport take maga hat last night ...\n4  &quot;The bigger question is, why are hundreds of p...    0.0             bigger question hundr peopl buse ralli",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>label</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"So after Biden wins, what do we do with the c...</td>\n      <td>0.0</td>\n      <td>biden win cult</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"  Please. \\nJust #RemovePelosi now.\\nShe is c...</td>\n      <td>1.0</td>\n      <td>pleas njust removepelosi nshe constantli lie n...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"  And I thought #TrumpSupporters were the bot...</td>\n      <td>0.0</td>\n      <td>thought trumpsupport bot trump http co r vgqv uob</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"Seeing a lot of #TrumpSupporters taking their...</td>\n      <td>0.0</td>\n      <td>see lot trumpsupport take maga hat last night ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"The bigger question is, why are hundreds of p...</td>\n      <td>0.0</td>\n      <td>bigger question hundr peopl buse ralli</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"So after Biden wins, what do we do with the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>biden win cult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"@GOPLeader @GoJackFlynn Please. \\nJust #Remov...</td>\n",
       "      <td>1</td>\n",
       "      <td>goplead gojackflynn pleas njust removepelosi n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"@Jeromep81422970 @stillgray And I thought #Tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>jeromep stillgray thought trumpsupport bot tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Seeing a lot of #TrumpSupporters taking their...</td>\n",
       "      <td>0</td>\n",
       "      <td>see lot trumpsupport take maga hat last night ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"The bigger question is, why are hundreds of p...</td>\n",
       "      <td>0</td>\n",
       "      <td>bigger question hundr peopl buse ralli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  label  \\\n",
       "0  \"So after Biden wins, what do we do with the c...      1   \n",
       "1  \"@GOPLeader @GoJackFlynn Please. \\nJust #Remov...      1   \n",
       "2  \"@Jeromep81422970 @stillgray And I thought #Tr...      0   \n",
       "3  \"Seeing a lot of #TrumpSupporters taking their...      0   \n",
       "4  \"The bigger question is, why are hundreds of p...      0   \n",
       "\n",
       "                                             cleaned  \n",
       "0                                     biden win cult  \n",
       "1  goplead gojackflynn pleas njust removepelosi n...  \n",
       "2  jeromep stillgray thought trumpsupport bot tru...  \n",
       "3  see lot trumpsupport take maga hat last night ...  \n",
       "4             bigger question hundr peopl buse ralli  "
      ]
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
     },
     "execution_count": 16,
     "metadata": {},
<<<<<<< HEAD
     "execution_count": 131
=======
     "output_type": "execute_result"
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
    }
   ],
   "source": [
    "#preprocess df_train\n",
    "start = time.time()\n",
    "\n",
    "data['cleaned'] = messages_preprocess(data[\"tweets\"])  #about 1 min\n",
    "\n",
    "end = time.time()\n",
    "print(\"time used:\",end - start)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
=======
   "execution_count": 17,
   "metadata": {},
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   "outputs": [
    {
     "name": "stdout",
<<<<<<< HEAD
     "text": "###################################################\nUncleaned bag of words size: (1594, 6014)\n###################################################\ncleaned bag of words size: (1594, 5148)\n###################################################\nUncleaned IT-IDF: (1594, 6014)\n###################################################\nCleaned IT-IDF: (1594, 5148)\n"
=======
     "output_type": "stream",
     "text": [
      "###################################################\n",
      "Uncleaned bag of words size: (254, 1896)\n",
      "###################################################\n",
      "cleaned bag of words size: (254, 1689)\n",
      "###################################################\n",
      "Uncleaned IT-IDF: (254, 1896)\n",
      "###################################################\n",
      "Cleaned IT-IDF: (254, 1689)\n"
     ]
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
    }
   ],
   "source": [
    "# creating the feature matrix \n",
    "\n",
    "#Bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=100000, min_df=1, max_df=0.7,stop_words=stopwords.words('english'))\n",
    "\n",
    "#with uncleaned messages\n",
    "count_vec = vectorizer.fit_transform(data['tweets'])\n",
    "count_vec = count_vec.toarray()\n",
    "print(\"###################################################\")\n",
    "print(\"Uncleaned bag of words size:\", count_vec.shape)\n",
    "\n",
    "#with cleaned messages\n",
    "count_vec_clean = vectorizer.fit_transform(data['cleaned'])\n",
    "count_vec_clean = count_vec_clean.toarray()\n",
    "print(\"###################################################\")\n",
    "print(\"cleaned bag of words size:\", count_vec_clean.shape)\n",
    "\n",
    "#Tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#with uncleaned messages\n",
    "tfidf_vec = TfidfVectorizer(max_features=100000, min_df=1, max_df=0.5,stop_words=stopwords.words('english'))\n",
    "tfidf_vec = tfidf_vec.fit_transform(data['tweets']).toarray()\n",
    "print(\"###################################################\")\n",
    "print(\"Uncleaned IT-IDF:\", tfidf_vec.shape)\n",
    "\n",
    "#with cleaned messages\n",
    "tfidf_vec_clean = TfidfVectorizer(max_features=100000, min_df=1, max_df=0.5,stop_words=stopwords.words('english'))\n",
    "tfidf_vec_clean = tfidf_vec_clean.fit_transform(data['cleaned']).toarray()\n",
    "print(\"###################################################\")\n",
    "print(\"Cleaned IT-IDF:\", tfidf_vec_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 133,
=======
   "execution_count": 22,
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose preprocessed data as training data\n",
    "processed_list = [count_vec, count_vec_clean, tfidf_vec, tfidf_vec_clean]\n",
    "processed_data = processed_list[2]  # [count_vec, count_vec_clean, tfidf_vec, tfidf_vec_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                tweets  label                                            cleaned\n403  &quot;The woman who was arrested and charged with a...    1.0  woman arrest charg attempt murder drive crowd ...\n395  &quot;‚Å¶‚Å© #BuildTheWall\\n\\nPriti Patel &#39;furious over...    0.0  buildthewal n npriti patel furiou asylum plan ...\n47   &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n55                                                 &quot;\\&quot;    0.0                                                   \n61   &quot;Biden REFUSED to use the term, LAW &amp;amp; ORDE...    0.0       biden refus use term law amp order go suburb\n78                                                 &quot;\\&quot;    0.0                                                   \n88   &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n123  &quot;850 Americans died of COVID-19 yesterday.\\nNo...    0.0  american die covid yesterday nnone got special...\n139                                                &quot;\\&quot;    0.0                                                   \n144  &quot;  ‚ÄúStand by‚Äù??? This white supremacist is lit...    0.0  stand white supremacist liter hold troop back ...\n173                                                &quot;\\&quot;    0.0                                                   \n194                                                &quot;\\&quot;    0.0                                                   \n216  &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n341  &quot;. was the dominant force last night. \\n \\nWhi...    0.0  domin forc last night n nwhile joe biden dodg ...\n351                                                &quot;\\&quot;    0.0                                                   \n368  &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n419                                                &quot;\\&quot;    0.0                                                   \n450  &quot;I vote  to be moderator for next debate!  She...    0.0  vote moder next debat shut trump bring misogyn...\n458  &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n459  &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n460   &quot;Going welI, I think! Thank you to all. LOVE!!!&quot;    0.0                           go weli think thank love\n489  &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n512                                                &quot;\\&quot;    0.0                                                   \n518  &quot;Compare how conservatives reacted to &amp;amp; mo...    0.0  compar conserv react amp mourn death rbg democ...\n522                            &quot; Your definition of \\&quot;    0.0                                            definit\n529  &quot;Tonight,  and I tested positive for COVID-19....    0.0  tonight test posit covid begin quarantin recov...\n535  &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n605  &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n623  &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n667                                                &quot;\\&quot;    0.0                                                   \n724  &quot; The Proud Boys very clearly got Trump&#39;s mess...    0.0  proud boy clearli got trump messag debat ackno...\n744  &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n745  &quot;OUR GREAT USA WANTS &amp;amp; NEEDS STIMULUS. WOR...    0.0  great usa want amp need stimulu work togeth ge...\n763  &quot; ‚ÄúStand by‚Äù??? This white supremacist is lite...    0.0  stand white supremacist liter hold troop back ...\n776  &quot;This is a good time to remind everyone that T...    0.0  good time remind everyon trump current taken c...\n787                                                &quot;\\&quot;    0.0                                                   ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>label</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>403</th>\n      <td>\"The woman who was arrested and charged with a...</td>\n      <td>1.0</td>\n      <td>woman arrest charg attempt murder drive crowd ...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>\"‚Å¶‚Å© #BuildTheWall\\n\\nPriti Patel 'furious over...</td>\n      <td>0.0</td>\n      <td>buildthewal n npriti patel furiou asylum plan ...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>\"\\\"</td>\n      <td>0.0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>\"Biden REFUSED to use the term, LAW &amp;amp; ORDE...</td>\n      <td>0.0</td>\n      <td>biden refus use term law amp order go suburb</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>\"\\\"</td>\n      <td>0.0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>\"850 Americans died of COVID-19 yesterday.\\nNo...</td>\n      <td>0.0</td>\n      <td>american die covid yesterday nnone got special...</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>\"\\\"</td>\n      <td>0.0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>\"  ‚ÄúStand by‚Äù??? This white supremacist is lit...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>\"\\\"</td>\n      <td>0.0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>\"\\\"</td>\n      <td>0.0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>216</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>\". was the dominant force last night. \\n \\nWhi...</td>\n      <td>0.0</td>\n      <td>domin forc last night n nwhile joe biden dodg ...</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>\"\\\"</td>\n      <td>0.0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>368</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>419</th>\n      <td>\"\\\"</td>\n      <td>0.0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>450</th>\n      <td>\"I vote  to be moderator for next debate!  She...</td>\n      <td>0.0</td>\n      <td>vote moder next debat shut trump bring misogyn...</td>\n    </tr>\n    <tr>\n      <th>458</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>459</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>460</th>\n      <td>\"Going welI, I think! Thank you to all. LOVE!!!\"</td>\n      <td>0.0</td>\n      <td>go weli think thank love</td>\n    </tr>\n    <tr>\n      <th>489</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>512</th>\n      <td>\"\\\"</td>\n      <td>0.0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>518</th>\n      <td>\"Compare how conservatives reacted to &amp;amp; mo...</td>\n      <td>0.0</td>\n      <td>compar conserv react amp mourn death rbg democ...</td>\n    </tr>\n    <tr>\n      <th>522</th>\n      <td>\" Your definition of \\\"</td>\n      <td>0.0</td>\n      <td>definit</td>\n    </tr>\n    <tr>\n      <th>529</th>\n      <td>\"Tonight,  and I tested positive for COVID-19....</td>\n      <td>0.0</td>\n      <td>tonight test posit covid begin quarantin recov...</td>\n    </tr>\n    <tr>\n      <th>535</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>605</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>623</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>\"\\\"</td>\n      <td>0.0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>724</th>\n      <td>\" The Proud Boys very clearly got Trump's mess...</td>\n      <td>0.0</td>\n      <td>proud boy clearli got trump messag debat ackno...</td>\n    </tr>\n    <tr>\n      <th>744</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>\"OUR GREAT USA WANTS &amp;amp; NEEDS STIMULUS. WOR...</td>\n      <td>0.0</td>\n      <td>great usa want amp need stimulu work togeth ge...</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>\" ‚ÄúStand by‚Äù??? This white supremacist is lite...</td>\n      <td>0.0</td>\n      <td>stand white supremacist liter hold troop back ...</td>\n    </tr>\n    <tr>\n      <th>776</th>\n      <td>\"This is a good time to remind everyone that T...</td>\n      <td>0.0</td>\n      <td>good time remind everyon trump current taken c...</td>\n    </tr>\n    <tr>\n      <th>787</th>\n      <td>\"\\\"</td>\n      <td>0.0</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "data[data.cleaned.duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
=======
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   "outputs": [],
   "source": [
    "# performance of count_vec(0.48) is worse than tfidf (0.54)\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(processed_data,\n",
    "                                                                                 data['label'], \n",
    "                                                                                 data.index, \n",
    "                                                                                 test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
=======
   "execution_count": 24,
   "metadata": {},
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
   "outputs": [
    {
     "output_type": "stream",
<<<<<<< HEAD
     "name": "stdout",
     "text": "########################################\nalpha =  0.1\nval acc =  0.7648902821316614\ntrain acc =  0.9764705882352941\n########################################\nalpha =  0.2\nval acc =  0.7586206896551724\ntrain acc =  0.9490196078431372\n########################################\nalpha =  0.30000000000000004\nval acc =  0.7617554858934169\ntrain acc =  0.9325490196078431\n########################################\nalpha =  0.4\nval acc =  0.7554858934169278\ntrain acc =  0.92\n########################################\nalpha =  0.5\nval acc =  0.7398119122257053\ntrain acc =  0.8933333333333333\n########################################\nalpha =  0.6\nval acc =  0.7272727272727273\ntrain acc =  0.8784313725490196\n########################################\nalpha =  0.7000000000000001\nval acc =  0.7115987460815048\ntrain acc =  0.8588235294117647\n########################################\nalpha =  0.8\nval acc =  0.7084639498432602\ntrain acc =  0.8486274509803922\n########################################\nalpha =  0.9\nval acc =  0.6990595611285266\ntrain acc =  0.8313725490196079\n########################################\nalpha =  1.0\nval acc =  0.6896551724137931\ntrain acc =  0.8086274509803921\n"
=======
     "text": [
      "########################################\n",
      "alpha =  0.1\n",
      "val acc =  0.7058823529411765\n",
      "train acc =  0.9950738916256158\n",
      "########################################\n",
      "alpha =  0.2\n",
      "val acc =  0.6862745098039216\n",
      "train acc =  0.9950738916256158\n",
      "########################################\n",
      "alpha =  0.30000000000000004\n",
      "val acc =  0.6862745098039216\n",
      "train acc =  0.9950738916256158\n",
      "########################################\n",
      "alpha =  0.4\n",
      "val acc =  0.7058823529411765\n",
      "train acc =  0.9901477832512315\n",
      "########################################\n",
      "alpha =  0.5\n",
      "val acc =  0.7254901960784313\n",
      "train acc =  0.9901477832512315\n",
      "########################################\n",
      "alpha =  0.6\n",
      "val acc =  0.6862745098039216\n",
      "train acc =  0.9901477832512315\n",
      "########################################\n",
      "alpha =  0.7000000000000001\n",
      "val acc =  0.6862745098039216\n",
      "train acc =  0.9802955665024631\n",
      "########################################\n",
      "alpha =  0.8\n",
      "val acc =  0.7058823529411765\n",
      "train acc =  0.9802955665024631\n",
      "########################################\n",
      "alpha =  0.9\n",
      "val acc =  0.7058823529411765\n",
      "train acc =  0.9802955665024631\n",
      "########################################\n",
      "alpha =  1.0\n",
      "val acc =  0.6862745098039216\n",
      "train acc =  0.9802955665024631\n"
     ]
>>>>>>> 4c2f986e70444c36f975fb9417477b3cc2db6f9c
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "test_acc_list = []\n",
    "train_acc_list = []\n",
    "alpha_list = [0.1 + x*0.1 for x in range(10)]\n",
    "for alpha in alpha_list:\n",
    "\n",
    "    model = MultinomialNB(alpha = alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"########################################\")\n",
    "    print(\"alpha = \", alpha)\n",
    "    \n",
    "    test_acc_list += [accuracy_score(y_test, y_pred)]\n",
    "    \n",
    "    print(\"val acc = \", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # performence on training set\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_acc_list += [accuracy_score(y_train_pred, y_train)]\n",
    "    print(\"train acc = \", accuracy_score(y_train_pred, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
